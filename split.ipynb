{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTOMES_ROOT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measurement = one session of one given subject\n",
    "connectome_measurements = set(tuple(fname.split(\"-\")[1::2]) for fname in os.listdir(CONNECTOMES_ROOT))\n",
    "len(connectome_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>scan_number</th>\n",
       "      <th>singleton</th>\n",
       "      <th>sedation</th>\n",
       "      <th>birth_age</th>\n",
       "      <th>scan_age</th>\n",
       "      <th>sex</th>\n",
       "      <th>birth_weight</th>\n",
       "      <th>head_circumference_scan</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_fmri_fieldmap_type</th>\n",
       "      <th>qc_fmri_dvars_z</th>\n",
       "      <th>qc_fmri_tsnr_z</th>\n",
       "      <th>qc_fmri_mcdc2sbref_z</th>\n",
       "      <th>qc_fmri_sbref2struct_z</th>\n",
       "      <th>qc_fmri_fmap2struct_z</th>\n",
       "      <th>qc_fmri_standard2struct_z</th>\n",
       "      <th>qc_fmri_flagged</th>\n",
       "      <th>qc_fmri_comment</th>\n",
       "      <th>qc_smri_pipeline_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC00050XX01</td>\n",
       "      <td>7201</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.29</td>\n",
       "      <td>female</td>\n",
       "      <td>3.91</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>failed fmri recon</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC00051XX02</td>\n",
       "      <td>7702</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>39.857143</td>\n",
       "      <td>40.00</td>\n",
       "      <td>female</td>\n",
       "      <td>3.31</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>failed fmri recon</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC00052XX03</td>\n",
       "      <td>8300</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.71</td>\n",
       "      <td>female</td>\n",
       "      <td>2.64</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>failed fmri recon</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC00053XX04</td>\n",
       "      <td>8607</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.43</td>\n",
       "      <td>female</td>\n",
       "      <td>3.46</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>failed fmri recon</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC00054XX05</td>\n",
       "      <td>8800</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>41.857143</td>\n",
       "      <td>42.14</td>\n",
       "      <td>male</td>\n",
       "      <td>3.69</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>failed fmri recon</td>\n",
       "      <td>full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  session_id  scan_number singleton  sedation  birth_age  \\\n",
       "0    CC00050XX01        7201            1         S     False  43.000000   \n",
       "1    CC00051XX02        7702            1         S     False  39.857143   \n",
       "2    CC00052XX03        8300            1         S     False  38.000000   \n",
       "3    CC00053XX04        8607            1         S     False  40.000000   \n",
       "4    CC00054XX05        8800            1         S     False  41.857143   \n",
       "\n",
       "   scan_age     sex  birth_weight  head_circumference_scan  ...  \\\n",
       "0     43.29  female          3.91                     37.0  ...   \n",
       "1     40.00  female          3.31                     35.0  ...   \n",
       "2     38.71  female          2.64                     33.0  ...   \n",
       "3     40.43  female          3.46                     32.0  ...   \n",
       "4     42.14    male          3.69                     35.0  ...   \n",
       "\n",
       "   qc_fmri_fieldmap_type  qc_fmri_dvars_z  qc_fmri_tsnr_z  \\\n",
       "0                    NaN              NaN             NaN   \n",
       "1                    NaN              NaN             NaN   \n",
       "2                    NaN              NaN             NaN   \n",
       "3                    NaN              NaN             NaN   \n",
       "4                    NaN              NaN             NaN   \n",
       "\n",
       "   qc_fmri_mcdc2sbref_z  qc_fmri_sbref2struct_z  qc_fmri_fmap2struct_z  \\\n",
       "0                   NaN                     NaN                    NaN   \n",
       "1                   NaN                     NaN                    NaN   \n",
       "2                   NaN                     NaN                    NaN   \n",
       "3                   NaN                     NaN                    NaN   \n",
       "4                   NaN                     NaN                    NaN   \n",
       "\n",
       "   qc_fmri_standard2struct_z  qc_fmri_flagged    qc_fmri_comment  \\\n",
       "0                        NaN             True  failed fmri recon   \n",
       "1                        NaN             True  failed fmri recon   \n",
       "2                        NaN             True  failed fmri recon   \n",
       "3                        NaN             True  failed fmri recon   \n",
       "4                        NaN             True  failed fmri recon   \n",
       "\n",
       "   qc_smri_pipeline_status  \n",
       "0                     full  \n",
       "1                     full  \n",
       "2                     full  \n",
       "3                     full  \n",
       "4                     full  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.read_csv(\"combined.tsv\", sep=\"\\t\")\n",
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_split_info(df: pd.DataFrame, task: str = \"birth_age\") -> None:\n",
    "    \"\"\"The following columns will be added to `df`:\n",
    "       - `meas_in_{task}_{split}` -> measurement (exactly the sub,ses pair) is in the given split of the task\n",
    "       - `subj_in_{task}_{split}` -> subj is part of the given split, but not necesarrily with this session\n",
    "    \"\"\"\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        df[[f\"meas_in_{task}_{split}\", f\"subj_in_{task}_{split}\"]] = False # add new columns\n",
    "        # get measurements in split as set of (sub, ses) tuples, and also a set of just the sub-s.\n",
    "        split_df = pd.read_csv(f\"splits/{task}_{split}.txt\", header=None)[0].str.split(\"[-_]\", expand=True)[[1, 3]]\n",
    "        split_measurements = set(tup[1:] for tup in split_df.itertuples(name=None))\n",
    "        split_subjects = set(sub for sub, _ in split_measurements)\n",
    "        assert len(split_measurements) == len(split_subjects), \"There must be at most one session for each subject\"\n",
    "        # add flags related to measurement and subect \n",
    "        for i, row in df.iterrows():\n",
    "            if (row.participant_id, str(row.session_id)) in split_measurements:\n",
    "                df.loc[i, f\"meas_in_{task}_{split}\"] = True\n",
    "            if row.participant_id in split_subjects:\n",
    "                df.loc[i, f\"subj_in_{task}_{split}\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_split_info(combined_df, task=\"scan_age\")\n",
    "add_split_info(combined_df, task=\"birth_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_has_connectome(df: pd.DataFrame, connectome_measurements: set[tuple[str]]) -> None:\n",
    "    df[\"has_connectome\"] = False\n",
    "    for i, row in df.iterrows():\n",
    "        if (row.participant_id, str(row.session_id)) in connectome_measurements:\n",
    "            df.loc[i, \"has_connectome\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_has_connectome(combined_df, connectome_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birth_age\ttrain:\t371\n",
      "birth_age\tval:\t51\n",
      "birth_age\ttest:\t49\n",
      "scan_age\ttrain:\t387\n",
      "scan_age\tval:\t52\n",
      "scan_age\ttest:\t51\n"
     ]
    }
   ],
   "source": [
    "# no. of measurements that are both in the original split and have connectome\n",
    "for task in [\"birth_age\", \"scan_age\"]:\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        num = (combined_df[\"has_connectome\"] & combined_df[f\"meas_in_{task}_{split}\"]).sum()\n",
    "        print(f\"{task}\\t{split}:\\t{num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birth_age\t#meas:\t149\n",
      "birth_age\t#subs:\t136\n",
      "scan_age\t#meas:\t139\n",
      "scan_age\t#subs:\t118\n"
     ]
    }
   ],
   "source": [
    "# no. of measurements/unique subjects that were in neither split but have connectome\n",
    "for task in [\"birth_age\", \"scan_age\"]:\n",
    "    mask = combined_df[\"has_connectome\"].copy() # without the copy() it will overwrite the column in the DF\n",
    "    for split in [\"train\", \"val\", \"test\"]: # mask: not part of any split\n",
    "        mask &= ~combined_df[f\"subj_in_{task}_{split}\"]\n",
    "    print(f\"{task}\\t#meas:\\t{mask.sum()}\")\n",
    "    n_unique = combined_df.loc[mask, \"participant_id\"].nunique()\n",
    "    print(f\"{task}\\t#subs:\\t{n_unique}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_splits(df: pd.DataFrame, task: str, n_samples: list[int]) -> None:\n",
    "    # mask: connectomes whose subject isn't in any original split of that task\n",
    "    # (=admissible measurements)\n",
    "    mask = df[\"has_connectome\"].copy()\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        mask &= ~df[f\"subj_in_{task}_{split}\"]\n",
    "\n",
    "    # additional_candidate = selected measurements from the pool of admissible measurements (=selected measurements)\n",
    "    # when we have >1 sessions per subject, we select the candidate session for the given subject based on the task:\n",
    "    # BA - we select the later measurement, SA - the earlier one\n",
    "    sa_group = df[mask].groupby(\"participant_id\")[\"scan_age\"]\n",
    "    additional_candidate_index = sa_group.idxmax() if task == \"birth_age\" else sa_group.idxmin()\n",
    "\n",
    "    # we assign the additional candidates\n",
    "    # assert sum(n_samples) == len(additional_candidate_index)\n",
    "    split_idx = np.array( [\"train\"]*n_samples[0] + [\"val\"]*n_samples[1] + [\"test\"]*n_samples[2] )\n",
    "    np.random.shuffle(split_idx)\n",
    "    split_dummies = pd.get_dummies(split_idx, prefix=f\"conn_{task}\")\n",
    "    df[split_dummies.columns] = False # adds columns: 'conn_{task}_train', 'conn_{task}_val', 'conn_{task}_test'\n",
    "    df.loc[additional_candidate_index, split_dummies.columns] = split_dummies.values # name the dummies according to new_cols\n",
    "\n",
    "    # we assign the rest\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        # connectomes whose measurement was in an original split get added automatically\n",
    "        is_conn_in_original = df[\"has_connectome\"] & df[f\"meas_in_{task}_{split}\"]\n",
    "        df.loc[is_conn_in_original, f\"conn_{task}_{split}\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birth_age\ttrain\t486\t[0.80]\n",
      "birth_age\tval\t60\t[0.10]\n",
      "birth_age\ttest\t61\t[0.10]\n",
      "scan_age\ttrain\t486\t[0.80]\n",
      "scan_age\tval\t61\t[0.10]\n",
      "scan_age\ttest\t61\t[0.10]\n"
     ]
    }
   ],
   "source": [
    "split_additional_samples = {\n",
    "    \"birth_age\": [115, 9, 12],\n",
    "    \"scan_age\": [99, 9, 10]\n",
    "}\n",
    "\n",
    "for task in [\"birth_age\", \"scan_age\"]:\n",
    "    assign_splits(combined_df, task=task, n_samples=split_additional_samples[task])\n",
    "    # pretty print\n",
    "    n_total_in_split = combined_df.loc[ :, combined_df.columns.str.contains(f\"conn_{task}\") ].values.sum(axis=None)\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        samples = combined_df[f\"conn_{task}_{split}\"].sum()\n",
    "        ratio = samples / n_total_in_split\n",
    "        print(f\"{task}\\t{split}\\t{samples}\\t[{ratio:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split():\n",
    "    for task in [\"birth_age\", \"scan_age\"]:\n",
    "        for split in [\"train\", \"val\", \"test\"]:  \n",
    "            split_df = combined_df[combined_df[f\"conn_{task}_{split}\"]]\n",
    "            series = \"sub-\" + split_df[\"participant_id\"] + \"_ses-\" + split_df[\"session_id\"].astype(str)\n",
    "            series.to_csv(f\"splits/connectome_{task}_{split}.txt\", header=None, index=None)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
